{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNMD5M6mQ2YY"
   },
   "source": [
    "# Coursework 3: RNNs\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "Please submit on CATe a zip file named *CW3_RNNs.zip* containing a version of this notebook with your answers. Write your answers in the cells below for each question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKehhGDF-Qte"
   },
   "source": [
    "## Recurrent models coursework\n",
    "\n",
    "This coursework is separated into a coding and a theory component.\n",
    "\n",
    "For the first part, you will use the Google Speech Commands v0.02 subset that you used in the RNN tutorial: http://www.doc.ic.ac.uk/~pam213/co460_files/ \n",
    "\n",
    "### Part 1 - Coding\n",
    "In this part you will have to:\n",
    "\n",
    "- Implement an LSTM\n",
    "- Implement a GRU\n",
    "\n",
    "### Part 2 - Theory\n",
    "\n",
    "Here you will answer some theoretical questions about RNNs -- no detailed proofs and no programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaI4P8SZ-U2j"
   },
   "source": [
    "### Part 1: Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWGb-eUeXtex"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "We will be using the Google [*Speech Commands*](https://www.tensorflow.org/tutorials/sequences/audio_recognition) v0.02 [1] dataset.\n",
    "\n",
    "[1] Warden, P. (2018). [Speech commands: A dataset for limited-vocabulary speech recognition](https://arxiv.org/abs/1804.03209). *arXiv preprint arXiv:1804.03209.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SURE THIS POINTS INSIDE THE DATASET FOLDER.\n",
    "dataset_folder = \"\" # this should change depending on where you have stored the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial code before coursework questions start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qt3KzJzBPdHU"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKSnqpAJLVwx"
   },
   "outputs": [],
   "source": [
    "class SpeechCommandsDataset(Dataset):\n",
    "    \"\"\"Google Speech Commands dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data files.\n",
    "            split    (string): In [\"train\", \"valid\", \"test\"].\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "\n",
    "        self.number_of_classes = len(self.get_classes())\n",
    "\n",
    "        self.class_to_file = defaultdict(list)\n",
    "\n",
    "        self.valid_filenames = self.get_valid_filenames()\n",
    "        self.test_filenames = self.get_test_filenames()\n",
    "\n",
    "        for c in self.get_classes():\n",
    "            file_name_list = sorted(os.listdir(self.root_dir + \"data_speech_commands_v0.02/\" + c))\n",
    "            for filename in file_name_list:\n",
    "                if split == \"train\":\n",
    "                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"valid\":\n",
    "                    if filename in self.valid_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"test\":\n",
    "                    if filename in self.test_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid split name.\")\n",
    "\n",
    "        self.filepath_list = list()\n",
    "        self.label_list = list()\n",
    "        for cc, c in enumerate(self.get_classes()):\n",
    "            f_extension = sorted(list(self.class_to_file[c]))\n",
    "            l_extension = [cc for i in f_extension]\n",
    "            f_extension = [self.root_dir + \"data_speech_commands_v0.02/\" + c + \"/\" + filename for filename in f_extension]\n",
    "            self.filepath_list.extend(f_extension)\n",
    "            self.label_list.extend(l_extension)\n",
    "        self.number_of_samples = len(self.filepath_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number_of_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = np.zeros((16000, ), dtype=np.float32)\n",
    "\n",
    "        sample_file = self.filepath_list[idx]\n",
    "\n",
    "        sample_from_file = read(sample_file)[1]\n",
    "        sample[:sample_from_file.size] = sample_from_file\n",
    "        sample = sample.reshape((16000, ))\n",
    "        \n",
    "        sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n",
    "\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def get_classes(self):\n",
    "        return ['one', 'two', 'three']\n",
    "\n",
    "    def get_valid_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/validation_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename\n",
    "\n",
    "    def get_test_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/testing_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vx8ptirGKa9u"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"train\")\n",
    "valid_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"valid\")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                     \"test\")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "valid_every_n_steps = 20\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJwOesOQOSh9"
   },
   "source": [
    "### Question 1:  Finalise the LSTM and GRU cells by completing the missing code\n",
    "\n",
    "You are allowed to use nn.Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQu9Yxfy-Wqj"
   },
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 1a) Complete the missing code\n",
    "        ########################################################################\n",
    "\n",
    "        self.x2h = \n",
    "        self.h2h = \n",
    "        \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "            hx = (hx, hx)\n",
    "            \n",
    "        # We used hx to pack both the hidden and cell states\n",
    "        hx, cx = hx\n",
    "        \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 1b) Complete the missing code\n",
    "        ########################################################################\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "\n",
    "        return (hy, cy)\n",
    "\n",
    "class BasicRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
    "        super(BasicRNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.nonlinearity = nonlinearity\n",
    "        if self.nonlinearity not in [\"tanh\", \"relu\"]:\n",
    "            raise ValueError(\"Invalid nonlinearity selected for RNN.\")\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "            \n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "\n",
    "        activation = getattr(nn.functional, self.nonlinearity)\n",
    "        hy = activation(self.x2h(input) + self.h2h(hx))\n",
    "\n",
    "        return hy\n",
    "\n",
    "    \n",
    "    \n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 1c) Complete the missing code\n",
    "        ########################################################################\n",
    "        self.x2h = \n",
    "        self.h2h = \n",
    "\n",
    "        self.x2r = \n",
    "        self.h2r =\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "        self.reset_parameters()\n",
    "        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "\n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 1d) Complete the missing code\n",
    "        ########################################################################\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "        \n",
    "        return hy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:  Finalise the RNNModel and BidirRecurrentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQu9Yxfy-Wqj"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        \n",
    "        if mode == 'LSTM':\n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2a) Complete the missing code\n",
    "        #\n",
    "        #  Append the appropriate LSTM cells to rnn_cell_list\n",
    "        ########################################################################\n",
    "    \n",
    "                \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ######################################################################## \n",
    "\n",
    "        elif mode == 'GRU':\n",
    "            \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2b) Complete the missing code\n",
    "        #\n",
    "        #  Append the appropriate GRU cells to rnn_cell_list\n",
    "        ########################################################################\n",
    "    \n",
    "\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################        \n",
    "        \n",
    "        elif mode == 'RNN_TANH':\n",
    "            \n",
    "                    \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2c) Complete the missing code\n",
    "        #\n",
    "        #  Append the appropriate RNN cells to rnn_cell_list\n",
    "        ########################################################################\n",
    "    \n",
    "\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "                \n",
    "        elif mode == 'RNN_RELU':\n",
    "            \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2d) Complete the missing code\n",
    "        #\n",
    "        #  Append the appropriate RNN cells to rnn_cell_list\n",
    "        ########################################################################\n",
    "        \n",
    "\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN mode selected.\")\n",
    "\n",
    "\n",
    "        self.att_fc = nn.Linear(self.hidden_size, 1)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        \n",
    "    def forward(self, input, hx=None):\n",
    "\n",
    "        outs = []\n",
    "        h0 = [None] * self.num_layers if hx is None else list(hx)\n",
    "        \n",
    "        # In this forward pass we want to create our RNN from the rnn cells,\n",
    "        # ..taking the hidden states from the final RNN layer and passing these \n",
    "        # ..through our fully connected layer (fc).\n",
    "        \n",
    "        # The multi-layered RNN should be able to run when the mode is either \n",
    "        # .. LSTM, GRU, RNN_TANH or RNN_RELU.\n",
    "        \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2e) Complete the missing code\n",
    "        #\n",
    "        #  HINT: You may need a special case for LSTMs\n",
    "        ########################################################################\n",
    "    \n",
    "    \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class BidirRecurrentModel(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(BidirRecurrentModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        self.rnn_cell_list_rev = nn.ModuleList()\n",
    "        \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE - Question 2f) Complete the missing code\n",
    "        #\n",
    "        #  Create code for the following 'mode' values:\n",
    "        # 'LSTM', 'GRU', 'RNN_TANH' and 'RNN_RELU'\n",
    "        ########################################################################\n",
    "        \n",
    "\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hx=None):\n",
    "        \n",
    "        # In this forward pass we want to create our Bidirectional RNN from the rnn cells,\n",
    "        # .. taking the hidden states from the final RNN layer with their reversed counterparts\n",
    "        # .. before concatening these and running them through the fully connected layer (fc)\n",
    "        \n",
    "        # The multi-layered RNN should be able to run when the mode is either \n",
    "        # .. LSTM, GRU, RNN_TANH or RNN_RELU.\n",
    "        \n",
    "        ########################################################################\n",
    "        ## START OF YOUR CODE  - Question 2g) Complete the missing code\n",
    "        ########################################################################\n",
    "        \n",
    "\n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "        out_rev = outs_rev[0].squeeze()\n",
    "        out = torch.cat((out, out_rev), 1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJwOesOQOSh9"
   },
   "source": [
    "The code below trains a network based on your code above. This should work without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQu9Yxfy-Wqj"
   },
   "outputs": [],
   "source": [
    "\n",
    "seq_dim, input_dim = train_dataset[0][0].shape\n",
    "output_dim = 3\n",
    "\n",
    "hidden_dim = 32\n",
    "layer_dim = 1\n",
    "bias = True\n",
    "\n",
    "### Change the code below to try running different models:\n",
    "#model = RNNModel(\"LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
    "model = BidirRecurrentModel(\"LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_list = []\n",
    "iter = 0\n",
    "max_v_accuracy = 0\n",
    "reported_t_accuracy = 0\n",
    "max_t_accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (audio, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(audio)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "\n",
    "        if iter % valid_every_n_steps == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for audio, labels in valid_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                outputs = model(audio)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            v_accuracy = 100 * correct // total\n",
    "            \n",
    "            is_best = False\n",
    "            if v_accuracy >= max_v_accuracy:\n",
    "                max_v_accuracy = v_accuracy\n",
    "                is_best = True\n",
    "\n",
    "            if is_best:\n",
    "                for audio, labels in test_loader:\n",
    "                    if torch.cuda.is_available():\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                    else:\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                    outputs = model(audio)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                    else:\n",
    "                        correct += (predicted == labels).sum()\n",
    "\n",
    "                t_accuracy = 100 * correct // total\n",
    "                reported_t_accuracy = t_accuracy\n",
    "\n",
    "            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0H6oJyOX-W7n"
   },
   "source": [
    "## Part 2: Theoretical questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CK0guD_b-ZAR"
   },
   "source": [
    "#### Theory question 1: \n",
    "What is the _vanishing gradients problem_ and why does it occur? Which activation functions are more or less impacted by this, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ha2y337Li6b4"
   },
   "source": [
    "#### Your answers:\n",
    "* Your answer here describing vanishing gradients problem\n",
    "* Two examples of activation functions more impacted by vanishing gradients\n",
    "* Two examples of activation functions less impacted by vanishing gradients, why are they impacted less?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory question 2: \n",
    "Why do LSTMs help address the vanishing gradient problem compared to a vanilla RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpefJuwe_c8o"
   },
   "source": [
    "#### Theory question 3: \n",
    "\n",
    "The plot below shows the training curves for three models A, B, and C, trained on the same dataset up to 100 epochs. The three models are a RNN, a LSTM and a GRU, not necessarily in that order.\n",
    "\n",
    "* Which could plausibly be which? Why? Please explain your reasoning.\n",
    "\n",
    "(In the cell below please set the values for A_model, B_model and C_model to be 'RNN', 'LSTM' or 'GRU'. This needs to be exact for the automatic marking.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "FBJJMuOUV-jJ",
    "outputId": "adcdcdfc-113e-4e4b-966f-43136ce69998",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='Performance by epoch.png', width=550))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Answers below:\n",
    "\n",
    "A_model = ''\n",
    "B_model = ''\n",
    "C_model = ''\n",
    "\n",
    "# Give your reasons below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory question 4: \n",
    "\n",
    "When might you choose to use each of the three different types of models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuLS-d3LkOUR"
   },
   "source": [
    "#### Your answers:\n",
    "* Type of problem when best to use vanilla RNN:\n",
    "* Type of problem to use GRU:\n",
    "* Type of problem to use LSTM:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36BpMC9uALUa"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fN1r5BqOkO7I"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN tutorial and coursework.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
